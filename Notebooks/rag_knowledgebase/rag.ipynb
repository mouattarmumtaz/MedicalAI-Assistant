{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a690f4fa",
   "metadata": {},
   "source": [
    "# rag_knowledgebase.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46e56f",
   "metadata": {},
   "source": [
    "## Load & chunk documents (TXT + PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd6eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs loaded: 179\n",
      "Chunks after cleaning: 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahin\\AppData\\Local\\Temp\\ipykernel_9292\\1543891062.py:64: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "C:\\Users\\mahin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "W0824 14:16:19.418000 9292 torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to D:\\\\MedicalAI-Assistant\\artifacts\\faiss_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\mahin\\AppData\\Local\\Temp\\ipykernel_9292\\1543891062.py:100: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipe)\n",
      "C:\\Users\\mahin\\AppData\\Local\\Temp\\ipykernel_9292\\1543891062.py:105: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(qa.run(\"What is the first-line treatment for ventilator-associated pneumonia?\"))\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chest physiotherapy\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "ROOT = r\"D:\\\\MedicalAI-Assistant\"\n",
    "BASE_DIR = os.path.join(ROOT, 'data')\n",
    "\n",
    "TEXTS: List[str] = []\n",
    "\n",
    "# single guidelines.txt\n",
    "guidelines_txt = os.path.join(BASE_DIR, 'guidelines.txt')\n",
    "if os.path.exists(guidelines_txt):\n",
    "    with open(guidelines_txt, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        TEXTS.append(f.read())\n",
    "\n",
    "# multiple .txt inside data/guidelines/\n",
    "G_DIR = os.path.join(BASE_DIR, 'guidelines')\n",
    "if os.path.isdir(G_DIR):\n",
    "    for path in glob.glob(os.path.join(G_DIR, '**', '*.txt'), recursive=True):\n",
    "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            TEXTS.append(f.read())\n",
    "\n",
    "#  Load PDF guidelines\n",
    "pdf_path = os.path.join(BASE_DIR, 'guidelines.pdf')\n",
    "if os.path.exists(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pdf_docs = loader.load()\n",
    "    TEXTS.extend([d.page_content for d in pdf_docs])\n",
    "\n",
    "print(\"Docs loaded:\", len(TEXTS))\n",
    "\n",
    "\n",
    "# Smart cleaning function\n",
    "def clean_text(text: str) -> str:\n",
    "    # normalize spaces/newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # preserve medical abbreviations (all-caps words), numbers, %, °C, subscript digits\n",
    "    # remove only strange symbols\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:%°()\\-–\\/\\[\\] ]+', ' ', text)\n",
    "\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Chunk documents \n",
    "CHUNKS = []\n",
    "for doc in TEXTS:\n",
    "    doc = clean_text(doc)\n",
    "    for i in range(0, len(doc), 800):  # 800 char chunks\n",
    "        CHUNKS.append(doc[i:i+800])\n",
    "\n",
    "print(\"Chunks after cleaning:\", len(CHUNKS))\n",
    "\n",
    "\n",
    "#  Build FAISS store \n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "emb = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "docs = [Document(page_content=ch) for ch in CHUNKS]\n",
    "vectorstore = FAISS.from_documents(docs, emb)\n",
    "\n",
    "SAVE_DIR = os.path.join(ROOT, 'artifacts', 'faiss_index')\n",
    "\n",
    "# clear old index and save new one\n",
    "import shutil\n",
    "shutil.rmtree(SAVE_DIR, ignore_errors=True)\n",
    "vectorstore.save_local(SAVE_DIR)\n",
    "\n",
    "print(\"FAISS index saved to\", SAVE_DIR)\n",
    "\n",
    "\n",
    "#  Quick QA test (local LLM) \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline as hf_pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load retriever\n",
    "retriever = FAISS.load_local(\n",
    "    SAVE_DIR, emb, allow_dangerous_deserialization=True\n",
    ").as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "# Local model for QA\n",
    "llm_tok = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "llm_mod = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')\n",
    "\n",
    "llm_pipe = hf_pipeline(\n",
    "    'text2text-generation',\n",
    "    model=llm_mod,\n",
    "    tokenizer=llm_tok,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipe)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type='stuff')\n",
    "\n",
    "# Example test\n",
    "print(qa.run(\"What is the first-line treatment for ventilator-associated pneumonia?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
