{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36634086",
   "metadata": {},
   "source": [
    "#  Utils for loading model and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d583be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, numpy as np, torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "_to_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def load_xray_model(weights_path: str, num_classes=2):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "    sd = torch.load(weights_path, map_location=DEVICE)\n",
    "    if isinstance(sd, dict) and 'state_dict' in sd:\n",
    "        model.load_state_dict(sd['state_dict'], strict=False)\n",
    "        classes = sd.get('classes', ['NORMAL','PNEUMONIA'])\n",
    "    else:\n",
    "        model.load_state_dict(sd, strict=False)\n",
    "        classes = ['NORMAL','PNEUMONIA']\n",
    "    model.eval().to(DEVICE)\n",
    "    return model, classes\n",
    "\n",
    "class TempCal:\n",
    "    def __init__(self, T=1.0):\n",
    "        self.T = float(T)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        if os.path.exists(path):\n",
    "            return cls(torch.load(path, map_location='cpu').get('T', 1.0))\n",
    "        return cls(1.0)\n",
    "\n",
    "def predict_xray(model, img):\n",
    "    if isinstance(img, (str, os.PathLike)):\n",
    "        img = Image.open(img).convert('RGB')\n",
    "    x = _to_resnet(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        idx = int(probs.argmax())\n",
    "    return idx, float(probs[idx]), probs.tolist()\n",
    "\n",
    "NORMAL_REPORT = (\n",
    "    \"Chest X-ray (PA):\\n\"\n",
    "    \"• Cardiomediastinal silhouette: Within normal limits.\\n\"\n",
    "    \"• Lungs: No focal consolidation identified. No pleural effusion.\\n\"\n",
    "    \"• Pneumothorax: Not seen.\\n\"\n",
    "    \"• Bones/soft tissues: Unremarkable.\\n\\n\"\n",
    "    \"Impression: No acute cardiopulmonary abnormality.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e2ea7",
   "metadata": {},
   "source": [
    "# X-RAY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd151da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_xray(img_path):\n",
    "    \"\"\"\n",
    "    Takes X-ray image path, preprocesses it,\n",
    "    runs the model, and returns predicted label(s).\n",
    "    \"\"\"\n",
    "    # Example stub — replace with your real model code\n",
    "    # model = load_model(...)\n",
    "    # img = preprocess(img_path)\n",
    "    # pred = model.predict(img)\n",
    "    # return decode_prediction(pred)\n",
    "    return \"Pneumonia (example)\"\n",
    "\n",
    "\n",
    "# ======================\n",
    "# REPORT SUMMARIZATION\n",
    "# ======================\n",
    "\n",
    "def summarize_report(report_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the input report into a concise version.\n",
    "    \"\"\"\n",
    "    # Example stub — replace with your summarizer\n",
    "    # summary = summarizer_pipeline(report_text)\n",
    "    # return summary\n",
    "    return \"This is a summary of the report.\"\n",
    "\n",
    "\n",
    "# ======================\n",
    "# RAG QUESTION ANSWERING\n",
    "# ======================\n",
    "\n",
    "def answer_query(query: str, report_text: str, xray_result: str) -> str:\n",
    "    \"\"\"\n",
    "    Answers user query using report text + xray classification + RAG.\n",
    "    \"\"\"\n",
    "    # Example stub — replace with your RAG pipeline\n",
    "    # context = build_context(report_text, xray_result)\n",
    "    # answer = rag_pipeline(query, context)\n",
    "    # return answer\n",
    "    return f\"Answer to '{query}' based on report and X-ray.\"\n",
    "\n",
    "\n",
    "# ======================\n",
    "# TEXT UTILS\n",
    "# ======================\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean text (remove extra spaces, normalize, etc.)\n",
    "    \"\"\"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ======================\n",
    "# MASTER PIPELINE\n",
    "# ======================\n",
    "\n",
    "def run_pipeline(xray_img, report_text, query):\n",
    "    \"\"\"\n",
    "    Complete pipeline:\n",
    "    1. Classify the X-ray\n",
    "    2. Summarize the report\n",
    "    3. Answer the user query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: classify X-ray\n",
    "        xray_result = classify_xray(xray_img)\n",
    "\n",
    "        # Step 2: summarize report\n",
    "        cleaned_report = preprocess_text(report_text)\n",
    "        summary_result = summarize_report(cleaned_report)\n",
    "\n",
    "        # Step 3: answer query using RAG\n",
    "        answer_result = answer_query(query, cleaned_report, xray_result)\n",
    "\n",
    "        return xray_result, summary_result, answer_result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", f\"Error: {str(e)}\", f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7743ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple, List, Optional\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# image transforms \n",
    "XRAY_TFMS = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#  small helper: find inner torch module from wrappers \n",
    "def _extract_torch_module(m):\n",
    "    if isinstance(m, nn.Module):\n",
    "        return m\n",
    "    # common wrapper attribute names\n",
    "    for name in [\"model\", \"network\", \"net\", \"module\", \"backbone\", \"base_model\"]:\n",
    "        if hasattr(m, name) and isinstance(getattr(m, name), nn.Module):\n",
    "            return getattr(m, name)\n",
    "    raise AttributeError(\"Could not find inner nn.Module inside the provided model/wrapper.\")\n",
    "\n",
    "def export_xray_checkpoint(\n",
    "    trained_model,\n",
    "    class_names: List[str],\n",
    "    export_path: str,\n",
    "    arch_hint: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves a universal checkpoint:\n",
    "      { 'state_dict': ..., 'classes': [...], 'arch': 'resnet18', 'num_classes': N }\n",
    "    Works whether trained_model is a wrapper or a plain nn.Module.\n",
    "    \"\"\"\n",
    "    torch_model = _extract_torch_module(trained_model)\n",
    "    # infer arch if not provided\n",
    "    arch = arch_hint or torch_model.__class__.__name__.lower()\n",
    "    # some wrappers keep the head as .fc (resnet) or .classifier (densenet/efficientnet)\n",
    "    if hasattr(torch_model, \"fc\") and isinstance(torch_model.fc, nn.Module):\n",
    "        out_features = getattr(torch_model.fc, \"out_features\", len(class_names))\n",
    "    elif hasattr(torch_model, \"classifier\") and isinstance(torch_model.classifier, nn.Module):\n",
    "        out_features = getattr(torch_model.classifier, \"out_features\", len(class_names))\n",
    "    else:\n",
    "        out_features = len(class_names)\n",
    "\n",
    "    payload = {\n",
    "        \"state_dict\": torch_model.state_dict(),\n",
    "        \"classes\": list(class_names),\n",
    "        \"arch\": arch,                \n",
    "        \"num_classes\": int(out_features),\n",
    "        \"input_size\": (224, 224),\n",
    "    }\n",
    "    os.makedirs(os.path.dirname(export_path), exist_ok=True)\n",
    "    torch.save(payload, export_path)\n",
    "    return export_path\n",
    "\n",
    "# mapping from arch name -> constructor + head patch \n",
    "def _build_backbone(arch: str, num_classes: int) -> nn.Module:\n",
    "    arch = (arch or \"resnet18\").lower()\n",
    "\n",
    "    if arch in [\"resnet18\", \"resnet-18\", \"resnet\"]:\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        in_feats = m.fc.in_features\n",
    "        m.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "        return m\n",
    "    if arch in [\"resnet34\", \"resnet-34\"]:\n",
    "        m = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        in_feats = m.fc.in_features\n",
    "        m.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "        return m\n",
    "    if arch in [\"resnet50\", \"resnet-50\"]:\n",
    "        m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        in_feats = m.fc.in_features\n",
    "        m.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "        return m\n",
    "    if arch in [\"densenet121\", \"densenet-121\", \"densenet\"]:\n",
    "        m = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        in_feats = m.classifier.in_features\n",
    "        m.classifier = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "        return m\n",
    "    # fallback\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    in_feats = m.fc.in_features\n",
    "    m.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
    "    return m\n",
    "\n",
    "# loader used by main \n",
    "def load_xray_model(checkpoint_path: str) -> Tuple[nn.Module, List[str]]:\n",
    "    \"\"\"\n",
    "    Loads from:\n",
    "      - universal dict: {'state_dict', 'classes', 'arch', 'num_classes'}\n",
    "      - OR plain state_dict (weights-only), defaulting to resnet18 + 2 classes\n",
    "    \"\"\"\n",
    "    ckpt = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        classes = ckpt.get(\"classes\", [\"NORMAL\", \"PNEUMONIA\"])\n",
    "        num_classes = ckpt.get(\"num_classes\", len(classes))\n",
    "        arch = ckpt.get(\"arch\", \"resnet18\")\n",
    "        model = _build_backbone(arch, num_classes)\n",
    "        model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n",
    "    else:\n",
    "        # weights-only: assume resnet18 with 2 classes\n",
    "        classes = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "        model = _build_backbone(\"resnet18\", len(classes))\n",
    "        model.load_state_dict(ckpt, strict=False)\n",
    "\n",
    "    model.eval().to(DEVICE)\n",
    "    return model, classes\n",
    "\n",
    "# prediction\n",
    "def predict_xray(model: nn.Module, img) -> Tuple[int, float, list]:\n",
    "    \"\"\"\n",
    "    Returns (pred_idx, conf, probs_list) with test-time flip averaging.\n",
    "    \"\"\"\n",
    "    if isinstance(img, (str, os.PathLike)):\n",
    "        img = Image.open(img).convert(\"RGB\")\n",
    "\n",
    "    x1 = XRAY_TFMS(img).unsqueeze(0).to(DEVICE)\n",
    "    x2 = XRAY_TFMS(img.transpose(Image.FLIP_LEFT_RIGHT)).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p1 = torch.softmax(model(x1), dim=1)\n",
    "        p2 = torch.softmax(model(x2), dim=1)\n",
    "        probs = ((p1 + p2) / 2.0).squeeze(0).cpu().numpy()\n",
    "\n",
    "    idx = int(probs.argmax())\n",
    "    return idx, float(probs[idx]), probs.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9e310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Absolute paths to artifacts so app runs from anywhere\n",
    "ROOT = r\"D:\\\\MedicalAI-Assistant\"\n",
    "ART_DIR = os.path.join(ROOT, 'artifacts')\n",
    "\n",
    "def load_xray_model(weights_path: str, class_names=('NORMAL','PNEUMONIA')):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    num_feats = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(num_feats, len(class_names))\n",
    "    )\n",
    "    sd = torch.load(weights_path, map_location=DEVICE)\n",
    "    model.load_state_dict(sd['state_dict'])\n",
    "    model.eval().to(DEVICE)\n",
    "    return model, sd.get('classes', list(class_names))\n",
    "\n",
    "_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "def predict_xray_with_roboflow(img_path):\n",
    "    pred, conf, _ = roboflow_classify(img_path)\n",
    "    return pred, conf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
